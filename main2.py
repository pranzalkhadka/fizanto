import os
from dotenv import load_dotenv
import pandas as pd
import ast
from groq import Groq
from io import StringIO
import sys
import requests


from dotenv import load_dotenv
from agno.vectordb.lancedb import LanceDb
from agno.embedder.fastembed import FastEmbedEmbedder
from typing import List, Dict, Optional, Tuple
from agno.agent import AgentKnowledge
    

knowledge_base = AgentKnowledge(
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="email_memory",
        embedder=FastEmbedEmbedder(id="BAAI/bge-small-en-v1.5")
    )
)


load_dotenv()

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
ATTACHMENT_DIR = "/app/attachments"
OUTPUT_DIR = "/app/output"

client = Groq(api_key=GROQ_API_KEY)

def get_csv_metadata(file_path: str) -> dict:
    try:
        df = pd.read_csv(file_path, encoding='utf-8')
        metadata = {
            "columns": list(df.columns),
            "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
            "shape": df.shape
        }
        return metadata
    except Exception as e:
        raise Exception(f"Failed to read CSV: {str(e)}")

def generate_analysis_code(metadata: dict, user_prompt: str, csv_path: str) -> str:
    system_prompt = "You are a data analyst that generates valid Python code for pandas data analysis."
    analysis_prompt = f"""
    Given the following CSV metadata and user prompt, generate Python code to analyze the data.

    Metadata:
    - Columns: {metadata['columns']}
    - Data types: {metadata['dtypes']}
    - Shape: {metadata['shape']}

    User Prompt: {user_prompt}

    Requirements:
    1. Import pandas as pd.
    2. Load the CSV using pd.read_csv('{csv_path}', encoding='utf-8').
    3. Perform data analysis based on the prompt, including:
       - Summary statistics for numeric columns
       - Value counts for at least one categorical column
    4. Print the analysis results as plain text using print().
    6. Return only valid Python code with correct indentation and complete syntax. Do not include comments, explanations, markdown, backticks, or incomplete statements.
    8. Ensure all print statements have closing parentheses.

    Example Code:
    import pandas as pd
    df = pd.read_csv('{csv_path}', encoding='utf-8')
    print("Summary Statistics:")
    print(df.select_dtypes(include=['float64', 'int64']).describe().to_string())
    print("Categorical Column Counts:")
    print(df.select_dtypes(include=['object']).columns[0] + " Counts:")
    print(df.select_dtypes(include=['object']).iloc[:, 0].value_counts().to_string())
    """
    try:
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": analysis_prompt},
            ]
        )
        code = response.choices[0].message.content.strip()
        # Clean the response to remove markdown and explanatory text
        code_lines = code.split('\n')
        cleaned_code = []
        in_code_block = False
        for line in code_lines:
            if line.strip().startswith('```'):
                in_code_block = not in_code_block
                continue
            if in_code_block or not line.strip().startswith(('Here is', 'This code')):
                cleaned_code.append(line)
        cleaned_code = '\n'.join(cleaned_code).strip()
        # Validate the generated code
        ast.parse(cleaned_code)
        return cleaned_code
    except SyntaxError as e:
        print(f"Invalid code generated by Groq:\n{cleaned_code}\nSyntax Error: {str(e)}")
        raise Exception(f"Generated code is invalid: {str(e)}")
    except Exception as e:
        raise Exception(f"Failed to generate code: {str(e)}")

def generate_human_readable_summary(metadata: dict, analysis_output: str) -> str:
    system_prompt = "You are an expert who can summarize data analysis results in plain English."
    user_prompt = f"""
    Given the following CSV metadata and raw analysis output, create a detailed summary of the key insights. First explain what the data is about, then summarize the key findings.

    Metadata:
    - Columns: {metadata['columns']}
    - Shape: {metadata['shape']}

    Raw Analysis Output:
    {analysis_output}
    """
    try:
        response = client.chat.completions.create(
            model="llama3-70b-8192",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        raise Exception(f"Failed to generate summary: {str(e)}")

def analyze_csv(csv_path: str, user_prompt: str) -> str:
    try:
        metadata = get_csv_metadata(csv_path)
        analysis_code = generate_analysis_code(metadata, user_prompt, csv_path)
        old_stdout = sys.stdout
        sys.stdout = mystdout = StringIO()
        exec(analysis_code)
        sys.stdout = old_stdout
        analysis_output = mystdout.getvalue()
        summary = generate_human_readable_summary(metadata, analysis_output)
        return summary
    except Exception as e:
        return f"Error analyzing CSV: {str(e)}"

def main():
    try:
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        response = requests.post("http://host.docker.internal:8000/process-email")
        response.raise_for_status()
        data = response.json()
        if data["status"] != "success":
            print("No unread emails or email processing failed.")
            return
        saved_files = data.get("saved_files", [])
        if not saved_files:
            print("No CSV attachments found.")
            return
        for csv_path in saved_files:
            csv_path = os.path.join(ATTACHMENT_DIR, os.path.basename(csv_path))
            if not os.path.exists(csv_path):
                print(f"File {csv_path} not found.")
                continue
            summary = analyze_csv(csv_path, "Give a simple analytics of this csv file")
            csv_filename = os.path.basename(csv_path)
            output_file = os.path.join(OUTPUT_DIR, f"analysis_summary_{csv_filename.replace('.csv', '')}.txt")
            with open(output_file, "w") as f:
                f.write(summary)
            print(f"Analysis summary saved to {output_file}")

            email_metadata_message = (
                f"Received an email from {data['email_sender']} at {data['email_timestamp']} "
                f"with subject {data['email_subject']} and body {data['email_body']} "
                f"identified as {data['email_id']}. "
                f"The email had an attachment named {csv_filename}. "
                f"Its analytics summary is {summary}."
            )

            knowledge_base.load_text(email_metadata_message)

    except Exception as e:
        print(f"Error processing email or CSV: {str(e)}")

if __name__ == "__main__":
    main()