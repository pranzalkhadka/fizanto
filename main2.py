# import os
# # from dotenv import load_dotenv
# import pandas as pd
# import ast
# from groq import Groq
# from io import StringIO
# import sys
# import requests

# # load_dotenv()
# # load_dotenv("/app/.env")  # Explicitly specify the .env file path
# # GROQ_API_KEY = os.getenv("GROQ_API_KEY")
# GROQ_API_KEY = "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"
# ATTACHMENT_DIR = "/app/attachments"
# OUTPUT_DIR = "/app/output"

# client = Groq(api_key=GROQ_API_KEY)

# def get_csv_metadata(file_path: str) -> dict:
#     try:
#         df = pd.read_csv(file_path, encoding='utf-8')
#         metadata = {
#             "columns": list(df.columns),
#             "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
#             "shape": df.shape
#         }
#         return metadata
#     except Exception as e:
#         raise Exception(f"Failed to read CSV: {str(e)}")

# def generate_analysis_code(metadata: dict, user_prompt: str) -> str:
#     system_prompt = "You are a data analyst that generates valid Python code for pandas data analysis."
#     analysis_prompt = f"""
#     Given the following CSV metadata and user prompt, generate Python code to analyze the data.

#     Metadata:
#     - Columns: {metadata['columns']}
#     - Data types: {metadata['dtypes']}
#     - Shape: {metadata['shape']}

#     User Prompt: {user_prompt}

#     Requirements:
#     1. Import pandas as pd.
#     2. Load the CSV using pd.read_csv('/app/input/banlk_loan.csv', encoding='utf-8').
#     3. Perform data analysis based on the prompt, including:
#        - Summary statistics for numeric columns
#        - Value counts for at least one categorical column
#     4. Print the analysis results as plain text using print().
#     6. Return only valid Python code with correct indentation and complete syntax. Do not include comments, explanations, markdown, backticks, or incomplete statements.
#     8. Ensure all print statements have closing parentheses.

#     Example Code:
#     import pandas as pd
#     df = pd.read_csv('/app/input/banlk_loan.csv', encoding='utf-8')
#     print("Summary Statistics:")
#     print(df[['Income', 'CCAvg']].describe().to_string())
#     print("Personal Loan Counts:")
#     print(df['Personal Loan'].value_counts().to_string())
#     """
#     try:
#         response = client.chat.completions.create(
#             model="llama3-70b-8192",
#             messages=[
#                 {"role": "system", "content": system_prompt},
#                 {"role": "user", "content": analysis_prompt},
#             ]
#         )
#         code = response.choices[0].message.content.strip()
#         ast.parse(code)
#         return code
#     except SyntaxError as e:
#         print(f"Invalid code generated by Groq:\n{code}\nSyntax Error: {str(e)}")
#         raise Exception(f"Generated code is invalid: {str(e)}")
#     except Exception as e:
#         raise Exception(f"Failed to generate code: {str(e)}")

# def generate_human_readable_summary(metadata: dict, analysis_output: str) -> str:
#     system_prompt = "You are an expert who can summarize data analysis results in plain English."
#     user_prompt = f"""
#     Given the following CSV metadata and raw analysis output, create a detailed summary of the key insights. First explain what the data is about, then summarize the key findings.

#     Metadata:
#     - Columns: {metadata['columns']}
#     - Shape: {metadata['shape']}

#     Raw Analysis Output:
#     {analysis_output}
#     """
#     try:
#         response = client.chat.completions.create(
#             model="llama3-70b-8192",
#             messages=[
#                 {"role": "system", "content": system_prompt},
#                 {"role": "user", "content": user_prompt},
#             ]
#         )
#         return response.choices[0].message.content.strip()
#     except Exception as e:
#         raise Exception(f"Failed to generate summary: {str(e)}")

# def analyze_csv(csv_path: str, user_prompt: str) -> str:
#     try:
#         metadata = get_csv_metadata(csv_path)
#         analysis_code = generate_analysis_code(metadata, user_prompt)
#         old_stdout = sys.stdout
#         sys.stdout = mystdout = StringIO()
#         exec(analysis_code)
#         sys.stdout = old_stdout
#         analysis_output = mystdout.getvalue()
#         summary = generate_human_readable_summary(metadata, analysis_output)
#         return summary
#     except Exception as e:
#         return f"Error analyzing CSV: {str(e)}"

# def main():
#     try:
#         os.makedirs(OUTPUT_DIR, exist_ok=True)
#         response = requests.post("http://host.docker.internal:8000/process-email")
#         data = response.json()
#         if data["status"] != "success":
#             print("No unread emails or email processing failed.")
#             return
#         saved_files = data.get("saved_files", [])
#         if not saved_files:
#             print("No CSV attachments found.")
#             return
#         for csv_path in saved_files:
#             csv_path = os.path.join(ATTACHMENT_DIR, os.path.basename(csv_path))
#             temp_csv_path = "/app/attachments/banlk_loan.csv"
#             summary = analyze_csv(temp_csv_path, "Give a simple analytics of this csv file")
#             os.remove(temp_csv_path)
#             csv_filename = os.path.basename(csv_path)
#             output_file = f"{OUTPUT_DIR}/analysis_summary_{csv_filename.replace('.csv', '')}.txt"
#             with open(output_file, "w") as f:
#                 f.write(summary)
#             print(f"Analysis summary saved to {output_file}")
#     except Exception as e:
#         print(f"Error processing email or CSV: {str(e)}")

# if __name__ == "__main__":
#     main()


import os
from dotenv import load_dotenv
import pandas as pd
import ast
from groq import Groq
from io import StringIO
import sys
import requests

load_dotenv()

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
ATTACHMENT_DIR = "/app/attachments"
OUTPUT_DIR = "/app/output"

client = Groq(api_key=GROQ_API_KEY)

def get_csv_metadata(file_path: str) -> dict:
    try:
        df = pd.read_csv(file_path, encoding='utf-8')
        metadata = {
            "columns": list(df.columns),
            "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
            "shape": df.shape
        }
        return metadata
    except Exception as e:
        raise Exception(f"Failed to read CSV: {str(e)}")

def generate_analysis_code(metadata: dict, user_prompt: str, csv_path: str) -> str:
    system_prompt = "You are a data analyst that generates valid Python code for pandas data analysis."
    analysis_prompt = f"""
    Given the following CSV metadata and user prompt, generate Python code to analyze the data.

    Metadata:
    - Columns: {metadata['columns']}
    - Data types: {metadata['dtypes']}
    - Shape: {metadata['shape']}

    User Prompt: {user_prompt}

    Requirements:
    1. Import pandas as pd.
    2. Load the CSV using pd.read_csv('{csv_path}', encoding='utf-8').
    3. Perform data analysis based on the prompt, including:
       - Summary statistics for numeric columns
       - Value counts for at least one categorical column
    4. Print the analysis results as plain text using print().
    6. Return only valid Python code with correct indentation and complete syntax. Do not include comments, explanations, markdown, backticks, or incomplete statements.
    8. Ensure all print statements have closing parentheses.

    Example Code:
    import pandas as pd
    df = pd.read_csv('{csv_path}', encoding='utf-8')
    print("Summary Statistics:")
    print(df.select_dtypes(include=['float64', 'int64']).describe().to_string())
    print("Categorical Column Counts:")
    print(df.select_dtypes(include=['object']).columns[0] + " Counts:")
    print(df.select_dtypes(include=['object']).iloc[:, 0].value_counts().to_string())
    """
    try:
        response = client.chat.completions.create(
            model="llama3-70b-8192",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": analysis_prompt},
            ]
        )
        code = response.choices[0].message.content.strip()
        ast.parse(code)
        return code
    except SyntaxError as e:
        print(f"Invalid code generated by Groq:\n{code}\nSyntax Error: {str(e)}")
        raise Exception(f"Generated code is invalid: {str(e)}")
    except Exception as e:
        raise Exception(f"Failed to generate code: {str(e)}")

def generate_human_readable_summary(metadata: dict, analysis_output: str) -> str:
    system_prompt = "You are an expert who can summarize data analysis results in plain English."
    user_prompt = f"""
    Given the following CSV metadata and raw analysis output, create a detailed summary of the key insights. First explain what the data is about, then summarize the key findings.

    Metadata:
    - Columns: {metadata['columns']}
    - Shape: {metadata['shape']}

    Raw Analysis Output:
    {analysis_output}
    """
    try:
        response = client.chat.completions.create(
            model="llama3-70b-8192",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        raise Exception(f"Failed to generate summary: {str(e)}")

def analyze_csv(csv_path: str, user_prompt: str) -> str:
    try:
        metadata = get_csv_metadata(csv_path)
        analysis_code = generate_analysis_code(metadata, user_prompt, csv_path)
        old_stdout = sys.stdout
        sys.stdout = mystdout = StringIO()
        exec(analysis_code)
        sys.stdout = old_stdout
        analysis_output = mystdout.getvalue()
        summary = generate_human_readable_summary(metadata, analysis_output)
        return summary
    except Exception as e:
        return f"Error analyzing CSV: {str(e)}"

def main():
    try:
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        response = requests.post("http://host.docker.internal:8000/process-email")
        response.raise_for_status()
        data = response.json()
        if data["status"] != "success":
            print("No unread emails or email processing failed.")
            return
        saved_files = data.get("saved_files", [])
        if not saved_files:
            print("No CSV attachments found.")
            return
        for csv_path in saved_files:
            csv_path = os.path.join(ATTACHMENT_DIR, os.path.basename(csv_path))
            if not os.path.exists(csv_path):
                print(f"File {csv_path} not found.")
                continue
            summary = analyze_csv(csv_path, "Give a simple analytics of this csv file")
            csv_filename = os.path.basename(csv_path)
            output_file = os.path.join(OUTPUT_DIR, f"analysis_summary_{csv_filename.replace('.csv', '')}.txt")
            with open(output_file, "w") as f:
                f.write(summary)
            print(f"Analysis summary saved to {output_file}")
    except Exception as e:
        print(f"Error processing email or CSV: {str(e)}")

if __name__ == "__main__":
    main()